{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier for lines\n",
    "\n",
    "This workbook builds a classifier for classifying the lines based on the exported data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLinesAll = pd.read_csv('./gerrit_review_for_classifier_wireshark.csv', sep='$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to replate the name of the column in case it is \"fit\"\n",
    "# this is a limitation of the classifiers in Python\n",
    "dfLinesAll = dfLinesAll.rename(columns = {'fit': 'fit_feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "class_value\n0    334\n1     73\nName: LOC, dtype: int64"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# this is just for our information\n",
    "# shows how balanced/imbalanced classes we have\n",
    "# for a good training accuracy, we need to have as close to 50-50 as possible\n",
    "dfLinesAll.groupby('class_value')['LOC'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfLinesAll.drop(['class_value', 'LOC', 'filename'], axis=1)\n",
    "y = dfLinesAll['class_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have unbalanced classes, we need to upsample/downsample\n",
    "# this script does the upsampling\n",
    "index_class_0 = np.where( y_train == 0 )[0]\n",
    "index_class_1 = np.where( y_train == 1 )[0]\n",
    "\n",
    "# Number of observations in each class\n",
    "n_class0 = len(index_class_0)\n",
    "n_class1 = len(index_class_1)\n",
    "\n",
    "# For every observation in class 0, randomly sample from class 1 with replacement\n",
    "i_class1_upsampled = np.random.choice(index_class_1, size=n_class0, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join together class 1's upsampled target vector with class 0's target vector\n",
    "y_train2 = np.concatenate((y_train[y_train.index[i_class1_upsampled]], y_train[y_train.index[index_class_0]]))\n",
    "X_train2 = np.concatenate((X_train.iloc[i_class1_upsampled], X_train.iloc[index_class_0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('std_scaler',\n                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n                ('ab',\n                 AdaBoostClassifier(algorithm='SAMME.R',\n                                    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n                                                                          class_weight=None,\n                                                                          criterion='gini',\n                                                                          max_depth=100,\n                                                                          max_features=None,\n                                                                          max_leaf_nodes=None,\n                                                                          min_impurity_decrease=0.0,\n                                                                          min_impurity_split=None,\n                                                                          min_samples_leaf=1,\n                                                                          min_samples_split=2,\n                                                                          min_weight_fraction_leaf=0.0,\n                                                                          presort='deprecated',\n                                                                          random_state=None,\n                                                                          splitter='best'),\n                                    learning_rate=0.2, n_estimators=200,\n                                    random_state=None))],\n         verbose=False)"
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "ab_pipeline = Pipeline([\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('ab', AdaBoostClassifier(DecisionTreeClassifier(max_depth=100), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.2)),\n",
    "    ])\n",
    "\n",
    "ab_pipeline.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.710, F1: 0.222\n"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "y_pred = ab_pipeline.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_ab)\n",
    "f1 = f1_score(y_test, y_pred_ab)\n",
    "\n",
    "print(f'Accuracy: {acc:.3f}, F1: {f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}